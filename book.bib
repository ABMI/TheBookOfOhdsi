@article{perkins2017principled,
  title={Principled approaches to missing data in epidemiologic studies},
  author={Perkins, Neil J and Cole, Stephen R and Harel, Ofer and Tchetgen Tchetgen, Eric J and Sun, BaoLuo and Mitchell, Emily M and Schisterman, Enrique F},
  journal={American journal of epidemiology},
  volume={187},
  number={3},
  pages={568--575},
  year={2017},
  publisher={Oxford University Press}
}

@Book{xie2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {http://yihui.name/knitr/},
}

@article{reps2018,
    author = {Reps, J. M.  and Schuemie, M. J.  and Suchard, M. A.  and Ryan, P. B.  and Rijnbeek, P. R. },
    title = "{{D}esign and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data}",
    journal = {Journal of the American Medical Informatics Association},
    volume = {25},
    number = {8},
    pages = {969-975},
    year = {2018},
    month = {04},
    issn = {1067-5027},
    doi = {10.1093/jamia/ocy032},
    url = {https://dx.doi.org/10.1093/jamia/ocy032},
    eprint = {http://oup.prod.sis.lan/jamia/article-pdf/25/8/969/27171328/ocy032.pdf},
}

@Article{nguyen2008,
   Author="Nguyen, N. D.  and Frost, S. A.  and Center, J. R.  and Eisman, J. A.  and Nguyen, T. V. ",
   Title="{{D}evelopment of prognostic nomograms for individualizing 5-year and 10-year fracture risks}",
   Journal="Osteoporos Int",
   Year="2008",
   Volume="19",
   Number="10",
   Pages="1431--1444",
   Month="Oct"
}

@Article{lee1995,
   Author="Lee, K. L.  and Woodlief, L. H.  and Topol, E. J.  and Weaver, W. D.  and Betriu, A.  and Col, J.  and Simoons, M.  and Aylward, P.  and Van de Werf, F.  and Califf, R. M. ",
   Title="{{P}redictors of 30-day mortality in the era of reperfusion for acute myocardial infarction. {R}esults from an international trial of 41,021 patients. {G}{U}{S}{T}{O}-{I} {I}nvestigators}",
   Journal="Circulation",
   Year="1995",
   Volume="91",
   Number="6",
   Pages="1659--1668",
   Month="Mar"
}

@Article{wilson1998,
   Author="Wilson, P. W.  and D'Agostino, R. B.  and Levy, D.  and Belanger, A. M.  and Silbershatz, H.  and Kannel, W. B. ",
   Title="{{P}rediction of coronary heart disease using risk factor categories}",
   Journal="Circulation",
   Year="1998",
   Volume="97",
   Number="18",
   Pages="1837--1847",
   Month="May"
}

@Article{engel2015,
   Author="Engel, C.  and Fischer, C. ",
   Title="{{B}reast cancer risks and risk prediction models}",
   Journal="Breast Care (Basel)",
   Year="2015",
   Volume="10",
   Number="1",
   Pages="7--12",
   Month="Feb"
}

@Article{perel2006,
   Author="Perel, P.  and Edwards, P.  and Wentz, R.  and Roberts, I. ",
   Title="{{S}ystematic review of prognostic models in traumatic brain injury}",
   Journal="BMC Med Inform Decis Mak",
   Year="2006",
   Volume="6",
   Pages="38",
   Month="Nov"
}

@Article{gage2001,
   Author="Gage, B. F.  and Waterman, A. D.  and Shannon, W.  and Boechler, M.  and Rich, M. W.  and Radford, M. J. ",
   Title="{{V}alidation of clinical classification schemes for predicting stroke: results from the {N}ational {R}egistry of {A}trial {F}ibrillation}",
   Journal="JAMA",
   Year="2001",
   Volume="285",
   Number="22",
   Pages="2864--2870",
   Month="Jun"
}

@Article{keogh2011,
   Author="Keogh, C.  and Wallace, E.  and Dillon, C.  and Dimitrov, B. D.  and Fahey, T. ",
   Title="{{V}alidation of the {C}{H}{A}{D}{S}2 clinical prediction rule to predict ischaemic stroke. {A} systematic review and meta-analysis}",
   Journal="Thromb. Haemost.",
   Year="2011",
   Volume="106",
   Number="3",
   Pages="528--538",
   Month="Sep"
}


@article{kahn_harmonized_2016,
	title = {A {Harmonized} {Data} {Quality} {Assessment} {Terminology} and {Framework} for the {Secondary} {Use} of {Electronic} {Health} {Record} {Data}},
	volume = {4},
	issn = {2327-9214},
	doi = {10.13063/2327-9214.1244},
	abstract = {OBJECTIVE: Harmonized data quality (DQ) assessment terms, methods, and reporting practices can establish a common understanding of the strengths and limitations of electronic health record (EHR) data for operational analytics, quality improvement, and research. Existing published DQ terms were harmonized to a comprehensive unified terminology with definitions and examples and organized into a conceptual framework to support a common approach to defining whether EHR data is 'fit' for specific uses.
MATERIALS AND METHODS: DQ publications, informatics and analytics experts, managers of established DQ programs, and operational manuals from several mature EHR-based research networks were reviewed to identify potential DQ terms and categories. Two face-to-face stakeholder meetings were used to vet an initial set of DQ terms and definitions that were grouped into an overall conceptual framework. Feedback received from data producers and users was used to construct a draft set of harmonized DQ terms and categories. Multiple rounds of iterative refinement resulted in a set of terms and organizing framework consisting of DQ categories, subcategories, terms, definitions, and examples. The harmonized terminology and logical framework's inclusiveness was evaluated against ten published DQ terminologies.
RESULTS: Existing DQ terms were harmonized and organized into a framework by defining three DQ categories: (1) Conformance (2) Completeness and (3) Plausibility and two DQ assessment contexts: (1) Verification and (2) Validation. Conformance and Plausibility categories were further divided into subcategories. Each category and subcategory was defined with respect to whether the data may be verified with organizational data, or validated against an accepted gold standard, depending on proposed context and uses. The coverage of the harmonized DQ terminology was validated by successfully aligning to multiple published DQ terminologies.
DISCUSSION: Existing DQ concepts, community input, and expert review informed the development of a distinct set of terms, organized into categories and subcategories. The resulting DQ terms successfully encompassed a wide range of disparate DQ terminologies. Operational definitions were developed to provide guidance for implementing DQ assessment procedures. The resulting structure is an inclusive DQ framework for standardizing DQ assessment and reporting. While our analysis focused on the DQ issues often found in EHR data, the new terminology may be applicable to a wide range of electronic health data such as administrative, research, and patient-reported data.
CONCLUSION: A consistent, common DQ terminology, organized into a logical framework, is an initial step in enabling data owners and users, patients, and policy makers to evaluate and communicate data quality findings in a well-defined manner with a shared vocabulary. Future work will leverage the framework and terminology to develop reusable data quality assessment and reporting methods.},
	language = {eng},
	number = {1},
	journal = {EGEMS (Washington, DC)},
	author = {Kahn, Michael G. and Callahan, Tiffany J. and Barnard, Juliana and Bauck, Alan E. and Brown, Jeff and Davidson, Bruce N. and Estiri, Hossein and Goerg, Carsten and Holve, Erin and Johnson, Steven G. and Liaw, Siaw-Teng and Hamilton-Lopez, Marianne and Meeker, Daniella and Ong, Toan C. and Ryan, Patrick and Shang, Ning and Weiskopf, Nicole G. and Weng, Chunhua and Zozus, Meredith N. and Schilling, Lisa},
	year = {2016},
	pmid = {27713905},
	pmcid = {PMC5051581},
	keywords = {data completeness, data use \& quality, electronic health records},
	pages = {1244}
}

@article{huser_methods_2018,
	title = {Methods for examining data quality in healthcare integrated data repositories},
	volume = {23},
	issn = {2335-6936},
	abstract = {This paper summarizes content of the workshop focused on data quality. The first speaker (VH) described data quality infrastructure and data quality evaluation methods currently in place within the Observational Data Science and Informatics (OHDSI) consortium. The speaker described in detail a data quality tool called Achilles Heel and latest development for extending this tool. Interim results of an ongoing Data Quality study within the OHDSI consortium were also presented. The second speaker (MK) described lessons learned and new data quality checks developed by the PEDsNet pediatric research network. The last two speakers (JB, RG) described tools developed by the Sentinel Initiative and University of Utah's service oriented framework. The workshop discussed at the end and throughout how data quality assessment can be advanced by combining best features of each network.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Huser, Vojtech and Kahn, Michael G. and Brown, Jeffrey S. and Gouripeddi, Ramkiran},
	year = {2018},
	pmid = {29218922},
	keywords = {Computational Biology, Computer Systems, Consumer Product Safety, Data Accuracy, Electronic Health Records, Humans, Sentinel Surveillance, United States},
	pages = {628--633}
}

@article{kahn_transparent_2015,
	title = {Transparent reporting of data quality in distributed data networks},
	volume = {3},
	issn = {2327-9214},
	doi = {10.13063/2327-9214.1052},
	abstract = {INTRODUCTION: Poor data quality can be a serious threat to the validity and generalizability of clinical research findings. The growing availability of electronic administrative and clinical data is accompanied by a growing concern about the quality of these data for observational research and other analytic purposes. Currently, there are no widely accepted guidelines for reporting quality results that would enable investigators and consumers to independently determine if a data source is fit for use to support analytic inferences and reliable evidence generation.
MODEL AND METHODS: We developed a conceptual model that captures the flow of data from data originator across successive data stewards and finally to the data consumer. This "data lifecycle" model illustrates how data quality issues can result in data being returned back to previous data custodians. We highlight the potential risks of poor data quality on clinical practice and research results. Because of the need to ensure transparent reporting of a data quality issues, we created a unifying data-quality reporting framework and a complementary set of 20 data-quality reporting recommendations for studies that use observational clinical and administrative data for secondary data analysis. We obtained stakeholder input on the perceived value of each recommendation by soliciting public comments via two face-to-face meetings of informatics and comparative-effectiveness investigators, through multiple public webinars targeted to the health services research community, and with an open access online wiki.
RECOMMENDATIONS: Our recommendations propose reporting on both general and analysis-specific data quality features. The goals of these recommendations are to improve the reporting of data quality measures for studies that use observational clinical and administrative data, to ensure transparency and consistency in computing data quality measures, and to facilitate best practices and trust in the new clinical discoveries based on secondary use of observational data.},
	language = {eng},
	number = {1},
	journal = {EGEMS (Washington, DC)},
	author = {Kahn, Michael G. and Brown, Jeffrey S. and Chun, Alein T. and Davidson, Bruce N. and Meeker, Daniella and Ryan, Patrick B. and Schilling, Lisa M. and Weiskopf, Nicole G. and Williams, Andrew E. and Zozus, Meredith Nahm},
	year = {2015},
	pmid = {25992385},
	pmcid = {PMC4434997},
	keywords = {comparative effectiveness, data use and quality, Informatics, observational data, research networks},
	pages = {1052}
}

@article{weiskopf_methods_2013,
	title = {Methods and dimensions of electronic health record data quality assessment: enabling reuse for clinical research},
	volume = {20},
	issn = {1527-974X},
	shorttitle = {Methods and dimensions of electronic health record data quality assessment},
	doi = {10.1136/amiajnl-2011-000681},
	abstract = {OBJECTIVE: To review the methods and dimensions of data quality assessment in the context of electronic health record (EHR) data reuse for research.
MATERIALS AND METHODS: A review of the clinical research literature discussing data quality assessment methodology for EHR data was performed. Using an iterative process, the aspects of data quality being measured were abstracted and categorized, as well as the methods of assessment used.
RESULTS: Five dimensions of data quality were identified, which are completeness, correctness, concordance, plausibility, and currency, and seven broad categories of data quality assessment methods: comparison with gold standards, data element agreement, data source agreement, distribution comparison, validity checks, log review, and element presence.
DISCUSSION: Examination of the methods by which clinical researchers have investigated the quality and suitability of EHR data for research shows that there are fundamental features of data quality, which may be difficult to measure, as well as proxy dimensions. Researchers interested in the reuse of EHR data for clinical research are recommended to consider the adoption of a consistent taxonomy of EHR data quality, to remain aware of the task-dependence of data quality, to integrate work on data quality assessment from other fields, and to adopt systematic, empirically driven, statistically based methods of data quality assessment.
CONCLUSION: There is currently little consistency or potential generalizability in the methods used to assess EHR data quality. If the reuse of EHR data for clinical research is to become accepted, researchers should adopt validated, systematic methods of EHR data quality assessment.},
	language = {eng},
	number = {1},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Weiskopf, Nicole Gray and Weng, Chunhua},
	month = jan,
	year = {2013},
	pmid = {22733976},
	pmcid = {PMC3555312},
	keywords = {Data Collection, Electronic Health Records, Humans, Information Dissemination, Quality Control, Reproducibility of Results, Research Design},
	pages = {144--151}
}
